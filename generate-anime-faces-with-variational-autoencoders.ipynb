{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generating anime faces with Variational Autoencoders (VAE)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, LeakyReLU, Dropout\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint \nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport os\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:05:02.351198Z","iopub.execute_input":"2021-10-11T12:05:02.351477Z","iopub.status.idle":"2021-10-11T12:05:08.441569Z","shell.execute_reply.started":"2021-10-11T12:05:02.351398Z","shell.execute_reply":"2021-10-11T12:05:08.440989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"WEIGHTS_FOLDER = '/kaggle/working/weights/'\nDATA_FOLDER = '/kaggle/input/animefacedataset/images//'\n\nif not os.path.exists(WEIGHTS_FOLDER):\n  os.makedirs(os.path.join(WEIGHTS_FOLDER,\"AE\"))\n  os.makedirs(os.path.join(WEIGHTS_FOLDER,\"VAE\"))\n\nfilenames = np.array(glob(os.path.join(DATA_FOLDER, '*.jpg')))\nNUM_IMAGES = len(filenames)\nprint(\"Total number of images : \" + str(NUM_IMAGES))","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:22:50.859431Z","iopub.execute_input":"2021-10-10T16:22:50.859851Z","iopub.status.idle":"2021-10-10T16:22:51.998697Z","shell.execute_reply.started":"2021-10-10T16:22:50.85982Z","shell.execute_reply":"2021-10-10T16:22:51.996748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_decoder(test=False, out_size=(64, 64)):\n    def decoder(path):\n        img = file_bytes = tf.io.read_file(path)\n        img = tf.image.decode_jpeg(file_bytes, channels=3)  \n        img = tf.image.resize(img, (64, 64))\n        img = tf.cast(img, tf.float32) / 255.0\n        return img\n    def decoder_train(path):\n        return decoder(path), decoder(path)\n\n    return decoder if test else decoder_train\n\ndef build_dataset(paths, test=False, shuffle=1, batch_size=1):\n    AUTO = tf.data.experimental.AUTOTUNE\n    decoder = build_decoder(test)\n\n    dset = tf.data.Dataset.from_tensor_slices(paths)\n    dset = dset.map(decoder, num_parallel_calls=AUTO)\n    \n    dset = dset.shuffle(shuffle)\n    dset = dset.batch(batch_size)\n    return dset","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:22:52.000538Z","iopub.execute_input":"2021-10-10T16:22:52.000927Z","iopub.status.idle":"2021-10-10T16:22:52.011006Z","shell.execute_reply.started":"2021-10-10T16:22:52.000872Z","shell.execute_reply":"2021-10-10T16:22:52.009762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIM = (64,64,3) # Image dimension\nBATCH_SIZE = 128\nZ_DIM = 100 # Dimension of the latent vector (z)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:22:52.013853Z","iopub.execute_input":"2021-10-10T16:22:52.014189Z","iopub.status.idle":"2021-10-10T16:22:52.02445Z","shell.execute_reply.started":"2021-10-10T16:22:52.01415Z","shell.execute_reply":"2021-10-10T16:22:52.023376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paths, valid_paths, _, _ = train_test_split(filenames, filenames, test_size=0.2, shuffle=True)\n\ntrain_dataset = build_dataset(train_paths, batch_size=128)\nvalid_dataset = build_dataset(valid_paths, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:22:52.025518Z","iopub.execute_input":"2021-10-10T16:22:52.026231Z","iopub.status.idle":"2021-10-10T16:22:54.600872Z","shell.execute_reply.started":"2021-10-10T16:22:52.026177Z","shell.execute_reply":"2021-10-10T16:22:54.599831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Autoencoder Model Definition","metadata":{}},{"cell_type":"code","source":"class ConvAutoencoder:\n    @staticmethod\n    def build(input_dim, latentDim=Z_DIM):\n        inputs = Input(shape = input_dim)\n        x = inputs\n        \n        for f in [32, 64, 64, 64]:\n            x = Conv2D(f, (3,3), strides=2, padding=\"same\")(x)\n            x = LeakyReLU()(x)\n        \n        volumeSize = K.int_shape(x)\n        x = Flatten()(x)\n        latent = Dense(latentDim)(x)\n        encoder = Model(inputs, latent, name = \"encoder\")\n        \n        print(encoder.summary())\n        \n        latentInputs = Input(shape=(latentDim,))\n        x = Dense(np.prod(volumeSize[1:]))(latentInputs)\n        x = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n        \n        for f in [64, 64, 32]:\n            x = Conv2DTranspose(f, (3, 3), strides=2, padding=\"same\")(x)\n            x = LeakyReLU()(x)\n\n        x = Conv2DTranspose(3, (3, 3), strides=2, padding=\"same\")(x)\n        outputs = Activation(\"sigmoid\")(x)\n\n        decoder = Model(latentInputs, outputs, name=\"decoder\")\n        \n        print(decoder.summary())\n        \n        autoencoder = Model(inputs, decoder(encoder(inputs)),name=\"autoencoder\")\n        \n        print(autoencoder.summary())\n        return (encoder, decoder, autoencoder)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:22:54.604719Z","iopub.execute_input":"2021-10-10T16:22:54.605Z","iopub.status.idle":"2021-10-10T16:22:54.62277Z","shell.execute_reply.started":"2021-10-10T16:22:54.604972Z","shell.execute_reply":"2021-10-10T16:22:54.619961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder, decoder, autoencoder = ConvAutoencoder.build(INPUT_DIM)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:22:54.624632Z","iopub.execute_input":"2021-10-10T16:22:54.624989Z","iopub.status.idle":"2021-10-10T16:22:55.244032Z","shell.execute_reply.started":"2021-10-10T16:22:54.62495Z","shell.execute_reply":"2021-10-10T16:22:55.243065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LEARNING_RATE = 0.0005\nN_EPOCHS = 10\n\noptimizer = Adam(lr = LEARNING_RATE)\n\ndef r_loss(y_true, y_pred):\n    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n\nautoencoder.compile(optimizer=optimizer, loss = r_loss)\n\ncheckpoint_ae_best = ModelCheckpoint(os.path.join(WEIGHTS_FOLDER, 'AE/ae_best_weights.h5'),\n                                     monitor='val_loss',\n                                     mode='min',\n                                     save_best_only=True,\n                                     save_weights_only = False, \n                                     verbose=1)\n\ncheckpoint_ae_last = ModelCheckpoint(os.path.join(WEIGHTS_FOLDER, 'AE/ae_last_weights.h5'),\n                                     monitor='val_loss',\n                                     mode='min',\n                                     save_best_only=False,\n                                     save_weights_only = False, \n                                     verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:22:55.247495Z","iopub.execute_input":"2021-10-10T16:22:55.247752Z","iopub.status.idle":"2021-10-10T16:22:55.270277Z","shell.execute_reply.started":"2021-10-10T16:22:55.247724Z","shell.execute_reply":"2021-10-10T16:22:55.269217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.fit(train_dataset,\n                epochs=10,\n                callbacks=[checkpoint_ae_best, checkpoint_ae_last],\n                validation_data=valid_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:22:55.272107Z","iopub.execute_input":"2021-10-10T16:22:55.272631Z","iopub.status.idle":"2021-10-10T16:31:03.580993Z","shell.execute_reply.started":"2021-10-10T16:22:55.272543Z","shell.execute_reply":"2021-10-10T16:31:03.579883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference using trained Autoencoder","metadata":{}},{"cell_type":"code","source":"test_dataset = build_dataset(valid_paths, test=True)\nautoencoder.load_weights('/kaggle/working/weights/AE/ae_last_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:31:03.584791Z","iopub.execute_input":"2021-10-10T16:31:03.585102Z","iopub.status.idle":"2021-10-10T16:31:03.629788Z","shell.execute_reply.started":"2021-10-10T16:31:03.585061Z","shell.execute_reply":"2021-10-10T16:31:03.628604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = list(test_dataset.take(20))\n\nfig = plt.figure(figsize=(30, 10))\nfor n in range(0, 20, 2):\n    image = autoencoder.predict(data[n])\n    \n    plt.subplot(2, 10, n + 1)\n    plt.imshow(np.squeeze(data[n]))\n    plt.title('original image')\n    \n    plt.subplot(2, 10, n + 2)\n    plt.imshow(np.squeeze(image))\n    plt.title('reconstruct')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:31:03.631603Z","iopub.execute_input":"2021-10-10T16:31:03.631987Z","iopub.status.idle":"2021-10-10T16:31:07.15305Z","shell.execute_reply.started":"2021-10-10T16:31:03.631934Z","shell.execute_reply":"2021-10-10T16:31:07.151828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Variable Autoencoder Model Definition","metadata":{}},{"cell_type":"code","source":"class VariableAutoencoder:\n    @staticmethod    \n    def build(input_shape=INPUT_DIM):\n\n        #Encoder\n        input_encoder = Input(shape=(input_shape))\n        x = Conv2D(32, kernel_size=(3, 3), strides = 2, padding='same', name='encoder_cov2d_1')(input_encoder)\n        x = LeakyReLU()(x)\n        x = Conv2D(64, kernel_size=(3, 3), strides = 2, padding='same', name='encoder_cov2d_2')(x)\n        x = LeakyReLU()(x)\n        x = Conv2D(64, kernel_size=(3, 3), strides = 2, padding='same', name='encoder_conv2d_3')(x)\n        x = LeakyReLU()(x)\n        x = Conv2D(64, kernel_size=(3, 3), strides = 2, padding='same', name='encoder_conv2d_4')(x)\n        volumeSize = K.int_shape(x)\n        x = Flatten()(x)\n\n        latent_mu = Dense(Z_DIM, name='latent_mean')(x)\n        latent_log_var = Dense(Z_DIM, name='latent_log_var')(x)\n        \n        def sampling(args=None):\n            z_mean, z_log_var = args\n            batch = K.shape(z_mean)[0]\n\n            epsilon = K.random_normal(shape=(batch, Z_DIM))\n            return z_mean + K.exp(0.5 * z_log_var) * epsilon\n        \n        latent_sample = Lambda(sampling)([latent_mu, latent_log_var])\n        encoder = Model(input_encoder, latent_sample, name='encoder')\n\n        latent_input = Input(shape=(Z_DIM,), name='decoder_input')\n        x = Dense(np.prod(volumeSize[1:]))(latent_input)\n        x = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n        x = Conv2DTranspose(64, kernel_size=(3, 3), strides=2, padding='same', name='conv2d_1')(x)\n        x = LeakyReLU()(x)\n        x = Conv2DTranspose(64, kernel_size=(3, 3), strides=2, padding='same', name='conv2d_2')(x)\n        x = LeakyReLU()(x)\n        x = Conv2DTranspose(32, kernel_size=(3, 3), strides=2, padding='same', name='conv2d_3')(x)\n        x = LeakyReLU()(x)\n        x = Conv2DTranspose(3, kernel_size=(3, 3), strides=2, padding='same', name='conv2d_4')(x)\n        output_decoder = Activation('sigmoid')(x)\n\n        decoder = Model(latent_input, output_decoder, name='decoder')\n\n        output_vae = decoder(encoder(input_encoder))\n        variable_autoencoder = Model(input_encoder, output_vae, name ='variable_autoencoder')\n\n        reconstruction_loss = binary_crossentropy(input_encoder, output_vae) * (64 * 64)\n        reconstruction_loss = K.mean(reconstruction_loss)\n\n        kl_loss = 1 + latent_log_var - K.square(latent_mu) - K.exp(latent_log_var)\n        kl_loss = K.sum(kl_loss, axis=-1)\n        kl_loss *= -0.5\n\n        vae_loss = K.mean(reconstruction_loss + kl_loss)\n\n        variable_autoencoder.add_loss(vae_loss)  \n        variable_autoencoder.add_metric(reconstruction_loss, name='reconstruction_loss')\n        variable_autoencoder.add_metric(kl_loss, name='kl_divergence_loss')\n\n        return variable_autoencoder, encoder, decoder","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:31:07.154574Z","iopub.execute_input":"2021-10-10T16:31:07.154875Z","iopub.status.idle":"2021-10-10T16:31:07.184575Z","shell.execute_reply.started":"2021-10-10T16:31:07.154838Z","shell.execute_reply":"2021-10-10T16:31:07.183059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var_autoencoder, var_encoder, var_decoder = VariableAutoencoder.build()\nvar_autoencoder.compile(optimizer='adam')\n\n# encoder.summary()\n# decoder.summary()\nvar_autoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:31:07.186271Z","iopub.execute_input":"2021-10-10T16:31:07.187234Z","iopub.status.idle":"2021-10-10T16:31:07.614907Z","shell.execute_reply.started":"2021-10-10T16:31:07.187193Z","shell.execute_reply":"2021-10-10T16:31:07.61381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Variable Autoencoder","metadata":{}},{"cell_type":"code","source":"VAE_N_EPOCHS = 10\ncheckpoint_vae_best = ModelCheckpoint(os.path.join(WEIGHTS_FOLDER, 'VAE/vae_best_model.h5'), \n                                      monitor='val_loss',\n                                      mode='min',\n                                      save_best_only=True,\n                                      save_weights_only = False, \n                                      verbose=1)\n    \ncheckpoint_vae_last = ModelCheckpoint(os.path.join(WEIGHTS_FOLDER, 'VAE/vae_last_model.h5'),\n                                      monitor='val_loss',\n                                      mode='min',\n                                      verbose=1,\n                                      save_best_only=False,\n                                      save_weights_only=False)\n\nvar_autoencoder.fit(train_dataset,\n                    epochs=VAE_N_EPOCHS,\n                    callbacks=[checkpoint_vae_best, checkpoint_vae_last],\n                    validation_data=valid_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:31:07.618359Z","iopub.execute_input":"2021-10-10T16:31:07.618672Z","iopub.status.idle":"2021-10-10T16:38:04.684587Z","shell.execute_reply.started":"2021-10-10T16:31:07.618645Z","shell.execute_reply":"2021-10-10T16:38:04.683599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding-Decoding using trained Variable Autoencoder","metadata":{}},{"cell_type":"code","source":"test_dataset = build_dataset(valid_paths, test=True)\nvar_autoencoder.load_weights(os.path.join(WEIGHTS_FOLDER, 'VAE/vae_last_model.h5'))","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:38:04.687338Z","iopub.execute_input":"2021-10-10T16:38:04.687658Z","iopub.status.idle":"2021-10-10T16:38:04.749444Z","shell.execute_reply.started":"2021-10-10T16:38:04.68762Z","shell.execute_reply":"2021-10-10T16:38:04.748615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = list(test_dataset.take(20))\n\nfig = plt.figure(figsize=(30, 10))\nfor n in range(0, 20, 2):\n    image = var_autoencoder.predict(data[n])\n    \n    plt.subplot(2, 10, n + 1)\n    plt.imshow(np.squeeze(data[n]))\n    plt.title('original image')\n    \n    plt.subplot(2, 10, n + 2)\n    plt.imshow(np.squeeze(image))\n    plt.title('reconstruct')\n    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:38:04.75118Z","iopub.execute_input":"2021-10-10T16:38:04.751514Z","iopub.status.idle":"2021-10-10T16:38:08.271935Z","shell.execute_reply.started":"2021-10-10T16:38:04.751469Z","shell.execute_reply":"2021-10-10T16:38:08.271113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate new anime faces using Variable Autoencoder","metadata":{}},{"cell_type":"code","source":"def vae_generate_images(n_to_show=20):\n    random_codes = np.random.normal(size=(n_to_show, Z_DIM))\n    new_faces = var_decoder.predict(np.array(random_codes))\n\n    fig = plt.figure(figsize=(30, 15))\n\n    for i in range(n_to_show):\n        ax = fig.add_subplot(6, 10, i+1)\n        ax.imshow(new_faces[i])\n        ax.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:38:08.273529Z","iopub.execute_input":"2021-10-10T16:38:08.273935Z","iopub.status.idle":"2021-10-10T16:38:08.282079Z","shell.execute_reply.started":"2021-10-10T16:38:08.273898Z","shell.execute_reply":"2021-10-10T16:38:08.280895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vae_generate_images(30)","metadata":{"execution":{"iopub.status.busy":"2021-10-10T16:40:06.438353Z","iopub.execute_input":"2021-10-10T16:40:06.438655Z","iopub.status.idle":"2021-10-10T16:40:08.65854Z","shell.execute_reply.started":"2021-10-10T16:40:06.438625Z","shell.execute_reply":"2021-10-10T16:40:08.657476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}